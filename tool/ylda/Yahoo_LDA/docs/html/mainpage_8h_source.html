<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<title>Y!LDA: src/mainpage.h Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<link href="doxygen.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<!-- Generated by Doxygen 1.6.3 -->
<div class="navigation" id="top">
  <div class="tabs">
    <ul>
      <li><a href="main.html"><span>Main&nbsp;Page</span></a></li>
      <li><a href="pages.html"><span>Related&nbsp;Pages</span></a></li>
      <li><a href="namespaces.html"><span>Namespaces</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li class="current"><a href="files.html"><span>Files</span></a></li>
    </ul>
  </div>
  <div class="tabs">
    <ul>
      <li><a href="files.html"><span>File&nbsp;List</span></a></li>
      <li><a href="globals.html"><span>File&nbsp;Members</span></a></li>
    </ul>
  </div>
<h1>src/mainpage.h</h1><a href="mainpage_8h.html">Go to the documentation of this file.</a><div class="fragment"><pre class="fragment"><a name="l00001"></a>00001 <span class="comment">/*****************************************************************************</span>
<a name="l00002"></a>00002 <span class="comment">     The contents of this file are subject to the Mozilla Public License</span>
<a name="l00003"></a>00003 <span class="comment">     Version 1.1 (the &quot;License&quot;); you may not use this file except in</span>
<a name="l00004"></a>00004 <span class="comment">     compliance with the License. You may obtain a copy of the License at</span>
<a name="l00005"></a>00005 <span class="comment">     http://www.mozilla.org/MPL/</span>
<a name="l00006"></a>00006 <span class="comment"></span>
<a name="l00007"></a>00007 <span class="comment">     Software distributed under the License is distributed on an &quot;AS IS&quot;</span>
<a name="l00008"></a>00008 <span class="comment">     basis, WITHOUT WARRANTY OF ANY KIND, either express or implied. See the</span>
<a name="l00009"></a>00009 <span class="comment">     License for the specific language governing rights and limitations</span>
<a name="l00010"></a>00010 <span class="comment">     under the License.</span>
<a name="l00011"></a>00011 <span class="comment"></span>
<a name="l00012"></a>00012 <span class="comment">     The Original Code is Copyright (C) by Yahoo! Research.</span>
<a name="l00013"></a>00013 <span class="comment"></span>
<a name="l00014"></a>00014 <span class="comment">     The Initial Developer of the Original Code is Shravan Narayanamurthy.</span>
<a name="l00015"></a>00015 <span class="comment"></span>
<a name="l00016"></a>00016 <span class="comment">     All Rights Reserved.</span>
<a name="l00017"></a>00017 <span class="comment">******************************************************************************/</span><span class="comment"></span>
<a name="l00018"></a>00018 <span class="comment">/** \mainpage Y!LDA Topic Modelling Framework</span>
<a name="l00019"></a>00019 <span class="comment"> * &lt;H1 CLASS=&quot;western&quot;&gt;What is Topic Modelling?&lt;/H1&gt;</span>
<a name="l00020"></a>00020 <span class="comment"> * &lt;P ALIGN=JUSTIFY STYLE=&quot;margin-bottom: 0cm&quot;&gt;</span>
<a name="l00021"></a>00021 <span class="comment"> * It is a Machine Learning technique to categorize data. If we have</span>
<a name="l00022"></a>00022 <span class="comment"> * to group the home pages of Singapore Airline, National University</span>
<a name="l00023"></a>00023 <span class="comment"> * of Singapore &amp; Chijmes which is a restaurant in Singapore, we can</span>
<a name="l00024"></a>00024 <span class="comment"> * group them as all belonging to Singapore. Now if we have more pages</span>
<a name="l00025"></a>00025 <span class="comment"> * to group lets say, United Airlines, Australian National University</span>
<a name="l00026"></a>00026 <span class="comment"> * and a restaurant in Berkeley, then we can group the combined set of</span>
<a name="l00027"></a>00027 <span class="comment"> * pages in multiple ways: by country, by type of business and so on.</span>
<a name="l00028"></a>00028 <span class="comment"> * Choosing one of these different ways is hard because each one of</span>
<a name="l00029"></a>00029 <span class="comment"> * them has multiple roles to play depending on the context. In a</span>
<a name="l00030"></a>00030 <span class="comment"> * document that talks about nations strengths then the grouping by</span>
<a name="l00031"></a>00031 <span class="comment"> * nationality is good and in some document which talks about universties</span>
<a name="l00032"></a>00032 <span class="comment"> * its apt to use the grouping by type of business.</span>
<a name="l00033"></a>00033 <span class="comment"> * So the only alternative is to assign or tag each page with all the</span>
<a name="l00034"></a>00034 <span class="comment"> * categories it belongs to. So we tag the United Airlines page as</span>
<a name="l00035"></a>00035 <span class="comment"> * an airliner company in US and so on.&lt;/P&gt;</span>
<a name="l00036"></a>00036 <span class="comment"> *</span>
<a name="l00037"></a>00037 <span class="comment"> * &lt;P ALIGN=JUSTIFY STYLE=&quot;margin-bottom: 0cm&quot;&gt;So whats the big</span>
<a name="l00038"></a>00038 <span class="comment"> * difference between grouping objects or clustering &amp; Topic Models?</span>
<a name="l00039"></a>00039 <span class="comment"> * The following example clarifies the distinction:</span>
<a name="l00040"></a>00040 <span class="comment"> * Consider objects of different colors. Clustering them is to find</span>
<a name="l00041"></a>00041 <span class="comment"> * that there are 3 prototypical colors RGB &amp; each object can be grouped</span>
<a name="l00042"></a>00042 <span class="comment"> * by what its primary color is. That is we group object by prototypes.</span>
<a name="l00043"></a>00043 <span class="comment"> * On the other hand with topic models we try to find the the composition</span>
<a name="l00044"></a>00044 <span class="comment"> * of RGB in the color of each object, that is we say that this color</span>
<a name="l00045"></a>00045 <span class="comment"> * is composed of 80% R, 9% G &amp; 11% B. So topic models are definitely</span>
<a name="l00046"></a>00046 <span class="comment"> * richer in the sense that any color can be decomposed into the</span>
<a name="l00047"></a>00047 <span class="comment"> * prototypical colors but not all colors can be unambiguously grouped&lt;/P&gt;</span>
<a name="l00048"></a>00048 <span class="comment"> *</span>
<a name="l00049"></a>00049 <span class="comment"> * &lt;H1 CLASS=&quot;western&quot;&gt;What is Y!LDA topic modelling framework?&lt;/H1&gt;</span>
<a name="l00050"></a>00050 <span class="comment"> * &lt;P ALIGN=JUSTIFY STYLE=&quot;margin-bottom: 0cm&quot;&gt;Though conceptually it</span>
<a name="l00051"></a>00051 <span class="comment"> * sounds very good, to make it work on 100s of millions of pages,</span>
<a name="l00052"></a>00052 <span class="comment"> * with 1000s of topics to infer &amp; no editorial data is a very hard</span>
<a name="l00053"></a>00053 <span class="comment"> * problem. The state of the art can only handle sizes that are 10</span>
<a name="l00054"></a>00054 <span class="comment"> * to 100 times smaller. We would also like the solution to scale</span>
<a name="l00055"></a>00055 <span class="comment"> * with the number of computers so that we can add more machines</span>
<a name="l00056"></a>00056 <span class="comment"> * and be able to solve bigger problems.&lt;/P&gt;</span>
<a name="l00057"></a>00057 <span class="comment"> *</span>
<a name="l00058"></a>00058 <span class="comment"> * &lt;P&gt;One way of solving the problem of Topic Modelling is called</span>
<a name="l00059"></a>00059 <span class="comment"> * &lt;a href=&quot;http://www.cs.princeton.edu/~blei/papers/BleiNgJordan2003.pdf&quot;&gt;Latent Dirichlet Allocation&lt;/a&gt;.</span>
<a name="l00060"></a>00060 <span class="comment"> * This is a statistical model which specifies a probabilistic procedure</span>
<a name="l00061"></a>00061 <span class="comment"> * to generate data. It defines a topic as a probability distribution over words.</span>
<a name="l00062"></a>00062 <span class="comment"> * Essentially think of topics as having a vocabulary of their own</span>
<a name="l00063"></a>00063 <span class="comment"> * with preference over words specified as a probability distribution.&lt;/P&gt;</span>
<a name="l00064"></a>00064 <span class="comment"> *</span>
<a name="l00065"></a>00065 <span class="comment"> * &lt;P&gt;We have implemented a framework to solve the topic modelling</span>
<a name="l00066"></a>00066 <span class="comment"> * problem using LDA which can work at very large scale. Considerable</span>
<a name="l00067"></a>00067 <span class="comment"> * effort has also been spent on creating an architecture for the</span>
<a name="l00068"></a>00068 <span class="comment"> * framework which is flexible enough to allow the reuse of infrastructure</span>
<a name="l00069"></a>00069 <span class="comment"> * for the implementation fancier models and extension. One of the</span>
<a name="l00070"></a>00070 <span class="comment"> * main aims here is that scaling a new model should take minimal effort.</span>
<a name="l00071"></a>00071 <span class="comment"> * For more details please take a look at</span>
<a name="l00072"></a>00072 <span class="comment"> * &lt;a href=&quot;http://portal.acm.org/citation.cfm?id=1920931&quot;&gt;An Architecture for Parallel Topic Models&lt;/a&gt;</span>
<a name="l00073"></a>00073 <span class="comment"> * &lt;/P&gt;</span>
<a name="l00074"></a>00074 <span class="comment"> *</span>
<a name="l00075"></a>00075 <span class="comment"> * &lt;P ALIGN=JUSTIFY STYLE=&quot;margin-bottom: 0cm&quot;&gt;&lt;BR&gt;</span>
<a name="l00076"></a>00076 <span class="comment"> * &lt;/P&gt;</span>
<a name="l00077"></a>00077 <span class="comment"> * &lt;H1 CLASS=&quot;western&quot;&gt;What does the framework provide?&lt;/H1&gt;</span>
<a name="l00078"></a>00078 <span class="comment"> * &lt;P ALIGN=JUSTIFY STYLE=&quot;margin-bottom: 0cm&quot;&gt;It provides a fast C++</span>
<a name="l00079"></a>00079 <span class="comment"> * implementation of the inferencing algorithm which can use both</span>
<a name="l00080"></a>00080 <span class="comment"> * multi-core parallelism and multi-machine parallelism using a hadoop</span>
<a name="l00081"></a>00081 <span class="comment"> * cluster. It can infer about a thousand topics on a million document</span>
<a name="l00082"></a>00082 <span class="comment"> * corpus while running for a thousand iterations on an eight core</span>
<a name="l00083"></a>00083 <span class="comment"> * machine in one day.&lt;/P&gt;</span>
<a name="l00084"></a>00084 <span class="comment"> * &lt;P ALIGN=JUSTIFY STYLE=&quot;margin-bottom: 0cm&quot;&gt;&lt;BR&gt;</span>
<a name="l00085"></a>00085 <span class="comment"> * &lt;/P&gt;</span>
<a name="l00086"></a>00086 <span class="comment"> * &lt;H1 CLASS=&quot;western&quot;&gt;What are the requirements?&lt;/H1&gt;</span>
<a name="l00087"></a>00087 <span class="comment"> * &lt;H2 CLASS=&quot;western&quot;&gt;Hardware Requirements:&lt;/H2&gt;</span>
<a name="l00088"></a>00088 <span class="comment"> * &lt;P&gt;&lt;B&gt;Small Corpus of the order of thousands of documents:&lt;/B&gt; Dual</span>
<a name="l00089"></a>00089 <span class="comment"> * Core machines with 4-8 GB of RAM might be sufficient. Of course you</span>
<a name="l00090"></a>00090 <span class="comment"> * can run the code on larger document sets but you will have to wait</span>
<a name="l00091"></a>00091 <span class="comment"> * longer or cut down on the number of iterations.&lt;/P&gt;</span>
<a name="l00092"></a>00092 <span class="comment"> * &lt;P ALIGN=JUSTIFY STYLE=&quot;margin-bottom: 0cm&quot;&gt;&lt;B&gt;Large Corpus of the</span>
<a name="l00093"></a>00093 <span class="comment"> * order of millions of documents:&lt;/B&gt;50 to 100 multi-Core (quad cores,</span>
<a name="l00094"></a>00094 <span class="comment"> * dual quad cores, etc) machines with 8 to 16 GB of RAM can give good</span>
<a name="l00095"></a>00095 <span class="comment"> * performance.&lt;/P&gt;</span>
<a name="l00096"></a>00096 <span class="comment"> * &lt;H2 CLASS=&quot;western&quot;&gt;Software Requirements:&lt;/H2&gt;</span>
<a name="l00097"></a>00097 <span class="comment"> * &lt;P&gt;The code has been mainly tested on the linux platform. If you want to</span>
<a name="l00098"></a>00098 <span class="comment"> * install on other platforms, since the source and libraries along with</span>
<a name="l00099"></a>00099 <span class="comment"> * source are provided, you can try compiling them and let us know if it</span>
<a name="l00100"></a>00100 <span class="comment"> * works.&lt;/P&gt;</span>
<a name="l00101"></a>00101 <span class="comment"> * &lt;H3 CLASS=&quot;western&quot;&gt;Dependencies:&lt;/H3&gt;</span>
<a name="l00102"></a>00102 <span class="comment"> * &lt;P&gt;The code has dependencies on a number of libraries. To facilitate</span>
<a name="l00103"></a>00103 <span class="comment"> * distribution we have hosted the libraries separately. The install script</span>
<a name="l00104"></a>00104 <span class="comment"> * shipped with the code fetches the sources for the associated libraries and</span>
<a name="l00105"></a>00105 <span class="comment"> * builds them on the developer&#39;s machine.</span>
<a name="l00106"></a>00106 <span class="comment"> * The following is the list: &lt;BR&gt;</span>
<a name="l00107"></a>00107 <span class="comment"> * &lt;OL&gt;</span>
<a name="l00108"></a>00108 <span class="comment"> * &lt;LI&gt;&lt;P ALIGN=JUSTIFY STYLE=&quot;margin-bottom: 0cm&quot;&gt;&lt;B&gt;Ice-3.4.1.tar.gz &lt;/B&gt;&lt;BR&gt;</span>
<a name="l00109"></a>00109 <span class="comment"> * An efficient inter process communication framework which is used for</span>
<a name="l00110"></a>00110 <span class="comment"> * the distributed storage of (topic, word) tables.&lt;/P&gt;</span>
<a name="l00111"></a>00111 <span class="comment"> * &lt;LI&gt;&lt;P ALIGN=JUSTIFY STYLE=&quot;margin-bottom: 0cm&quot;&gt;&lt;B&gt;cppunit-1.12.1.tar.gz &lt;/B&gt;&lt;BR&gt;</span>
<a name="l00112"></a>00112 <span class="comment"> * C++ unit testing framework. We use this for unit tests.&lt;/P&gt;</span>
<a name="l00113"></a>00113 <span class="comment"> * &lt;LI&gt;&lt;P ALIGN=JUSTIFY STYLE=&quot;margin-bottom: 0cm&quot;&gt;&lt;B&gt;mcpp-2.7.2.tar.gz &lt;/B&gt;&lt;BR&gt;</span>
<a name="l00114"></a>00114 <span class="comment"> * C++ preprocessor&lt;/P&gt;</span>
<a name="l00115"></a>00115 <span class="comment"> * &lt;LI&gt;&lt;P ALIGN=JUSTIFY STYLE=&quot;margin-bottom: 0cm&quot;&gt;&lt;B&gt;boostinclude.tar.gz &lt;/B&gt;&lt;BR&gt;</span>
<a name="l00116"></a>00116 <span class="comment"> * Boost libraries (various datatypes)&lt;/P&gt;</span>
<a name="l00117"></a>00117 <span class="comment"> * &lt;LI&gt;&lt;P ALIGN=JUSTIFY STYLE=&quot;margin-bottom: 0cm&quot;&gt;&lt;B&gt;gflags-1.2.tar.gz &lt;/B&gt;&lt;BR&gt;</span>
<a name="l00118"></a>00118 <span class="comment"> * Google&#39;s flag processing library (used for commandline options)&lt;/P&gt;</span>
<a name="l00119"></a>00119 <span class="comment"> * &lt;LI&gt;&lt;P ALIGN=JUSTIFY STYLE=&quot;margin-bottom: 0cm&quot;&gt;&lt;B&gt;protobuf-2.2.0a.tar.gz &lt;/B&gt;&lt;BR&gt;</span>
<a name="l00120"></a>00120 <span class="comment"> * Protocol buffers (used for serializing data to disk and as internal</span>
<a name="l00121"></a>00121 <span class="comment"> * key data structure). Google&#39;s serialization library&lt;/P&gt;</span>
<a name="l00122"></a>00122 <span class="comment"> * &lt;LI&gt;&lt;P ALIGN=JUSTIFY STYLE=&quot;margin-bottom: 0cm&quot;&gt;&lt;B&gt;bzip2-1.0.5.tar.gz &lt;/B&gt;&lt;BR&gt;</span>
<a name="l00123"></a>00123 <span class="comment"> * Data compression&lt;/P&gt;</span>
<a name="l00124"></a>00124 <span class="comment"> * &lt;LI&gt;&lt;P ALIGN=JUSTIFY STYLE=&quot;margin-bottom: 0cm&quot;&gt;&lt;B&gt;glog-0.3.0.tar.gz &lt;/B&gt;&lt;BR&gt;</span>
<a name="l00125"></a>00125 <span class="comment"> * Logfile generation (Google&#39;s log library).&lt;/P&gt;</span>
<a name="l00126"></a>00126 <span class="comment"> * &lt;LI&gt;&lt;P ALIGN=JUSTIFY STYLE=&quot;margin-bottom: 0cm&quot;&gt;&lt;B&gt;tbb22_20090809oss.tar.gz &lt;/B&gt;&lt;BR&gt;</span>
<a name="l00127"></a>00127 <span class="comment"> * Intel Threading Building Blocks. Multithreaded processing</span>
<a name="l00128"></a>00128 <span class="comment"> * library. Much easier to use than pthreads. We use the pipeline</span>
<a name="l00129"></a>00129 <span class="comment"> * class.&lt;/P&gt;</span>
<a name="l00130"></a>00130 <span class="comment"> * &lt;/OL&gt;</span>
<a name="l00131"></a>00131 <span class="comment"> * All the libraries except Ice should install without</span>
<a name="l00132"></a>00132 <span class="comment"> * problems. With Ice, there are a lot dependencies involved and our</span>
<a name="l00133"></a>00133 <span class="comment"> * automated build script might not work in your set-up. If so please</span>
<a name="l00134"></a>00134 <span class="comment"> * install Ice manually and copy the required includes &amp; libs into</span>
<a name="l00135"></a>00135 <span class="comment"> * the Yahoo_LDA directory&lt;/B&gt;&lt;/P&gt;</span>
<a name="l00136"></a>00136 <span class="comment"> * &lt;H1 CLASS=&quot;western&quot;&gt;How do you install?&lt;/H1&gt;</span>
<a name="l00137"></a>00137 <span class="comment"> * &lt;OL&gt;</span>
<a name="l00138"></a>00138 <span class="comment"> *  &lt;LI&gt;&lt;P ALIGN=JUSTIFY STYLE=&quot;margin-bottom: 0cm&quot;&gt;Run make from the</span>
<a name="l00139"></a>00139 <span class="comment"> *  directory where you have checked out the source.&lt;/P&gt;</span>
<a name="l00140"></a>00140 <span class="comment"> *  &lt;LI&gt;&lt;P ALIGN=JUSTIFY STYLE=&quot;margin-bottom: 0cm&quot;&gt;This will first</span>
<a name="l00141"></a>00141 <span class="comment"> *  install all the required libraries locally in the same directory. It</span>
<a name="l00142"></a>00142 <span class="comment"> *  will then compile the source code to generate the binaries described</span>
<a name="l00143"></a>00143 <span class="comment"> *  next.&lt;/P&gt;</span>
<a name="l00144"></a>00144 <span class="comment"> *  &lt;LI&gt;&lt;P ALIGN=JUSTIFY STYLE=&quot;margin-bottom: 0cm&quot;&gt;Please check for a</span>
<a name="l00145"></a>00145 <span class="comment"> *  proper install before if you see compilation or linkage errors.</span>
<a name="l00146"></a>00146 <span class="comment"> *  There may be issues with installation of Ice. Care has been taken</span>
<a name="l00147"></a>00147 <span class="comment"> *  that the install happens on most well set-up machines but if it</span>
<a name="l00148"></a>00148 <span class="comment"> *  fails, we recommend installing Ice manually and copying the include</span>
<a name="l00149"></a>00149 <span class="comment"> *  files and the libraries to the include &amp;amp; lib directories in the</span>
<a name="l00150"></a>00150 <span class="comment"> *  Y!LDA install path. After this the compilation should go through</span>
<a name="l00151"></a>00151 <span class="comment"> *  fine.&lt;/P&gt;</span>
<a name="l00152"></a>00152 <span class="comment"> * &lt;/OL&gt;</span>
<a name="l00153"></a>00153 <span class="comment"> * &lt;P ALIGN=JUSTIFY STYLE=&quot;margin-bottom: 0cm&quot;&gt;&lt;BR&gt;</span>
<a name="l00154"></a>00154 <span class="comment"> * &lt;/P&gt;</span>
<a name="l00155"></a>00155 <span class="comment"> * &lt;H1 CLASS=&quot;western&quot;&gt;What are the binaries that get installed and what</span>
<a name="l00156"></a>00156 <span class="comment"> * do you use them for?&lt;/H1&gt;</span>
<a name="l00157"></a>00157 <span class="comment"> * &lt;OL&gt;</span>
<a name="l00158"></a>00158 <span class="comment"> *  &lt;LI&gt;&lt;P ALIGN=JUSTIFY STYLE=&quot;margin-bottom: 0cm&quot;&gt;formatter : Used to</span>
<a name="l00159"></a>00159 <span class="comment"> *  format the raw text corpus into a binary format on which learntopics</span>
<a name="l00160"></a>00160 <span class="comment"> *  can be run. This is a preprocessing step that allows one to run</span>
<a name="l00161"></a>00161 <span class="comment"> *  learntopics many times on the same corpus. It also decreases the on</span>
<a name="l00162"></a>00162 <span class="comment"> *  disk size of the raw text corpus.&lt;/P&gt;</span>
<a name="l00163"></a>00163 <span class="comment"> *  &lt;LI&gt;&lt;P ALIGN=JUSTIFY STYLE=&quot;margin-bottom: 0cm&quot;&gt;learntopics: Used to</span>
<a name="l00164"></a>00164 <span class="comment"> *  learn/infer the topics from the corpus and represent the documents</span>
<a name="l00165"></a>00165 <span class="comment"> *  in the corpus as mixture of these topics.&lt;/P&gt;</span>
<a name="l00166"></a>00166 <span class="comment"> *  &lt;LI&gt;&lt;P ALIGN=JUSTIFY STYLE=&quot;margin-bottom: 0cm&quot;&gt;DM_Server: This is</span>
<a name="l00167"></a>00167 <span class="comment"> *  the server that implements a distributed hash table that is used to</span>
<a name="l00168"></a>00168 <span class="comment"> *  store the global counts table while running the multi-machine</span>
<a name="l00169"></a>00169 <span class="comment"> *  version of the code.&lt;/P&gt;</span>
<a name="l00170"></a>00170 <span class="comment"> *  &lt;LI&gt;&lt;P ALIGN=JUSTIFY STYLE=&quot;margin-bottom: 0cm&quot;&gt;Merge_Dictionaries:</span>
<a name="l00171"></a>00171 <span class="comment"> *  This is used to build the global dictionary by merging the local</span>
<a name="l00172"></a>00172 <span class="comment"> *  dictionaries&lt;/P&gt;</span>
<a name="l00173"></a>00173 <span class="comment"> *  &lt;LI&gt;&lt;P ALIGN=JUSTIFY STYLE=&quot;margin-bottom: 0cm&quot;&gt;Merge_Topic_Counts:</span>
<a name="l00174"></a>00174 <span class="comment"> *  This is used to dump the global counts table to disk.&lt;/P&gt;</span>
<a name="l00175"></a>00175 <span class="comment"> * &lt;/OL&gt;</span>
<a name="l00176"></a>00176 <span class="comment"> * &lt;P ALIGN=JUSTIFY STYLE=&quot;margin-bottom: 0cm&quot;&gt;&lt;BR&gt;</span>
<a name="l00177"></a>00177 <span class="comment"> * &lt;/P&gt;</span>
<a name="l00178"></a>00178 <span class="comment"> * &lt;H1 CLASS=&quot;western&quot;&gt;What are the scripts available and what do you do</span>
<a name="l00179"></a>00179 <span class="comment"> * with them?&lt;/H1&gt;</span>
<a name="l00180"></a>00180 <span class="comment"> * &lt;P ALIGN=JUSTIFY STYLE=&quot;margin-bottom: 0cm&quot;&gt;Scripts are available for</span>
<a name="l00181"></a>00181 <span class="comment"> * the use of build system and the multi-machine setup with Hadoop. The</span>
<a name="l00182"></a>00182 <span class="comment"> * build system uses the bin/create*.sh scripts to find out files &amp;amp;</span>
<a name="l00183"></a>00183 <span class="comment"> * directories. The multi-machine setup has the runLDA.sh, Formatter.sh</span>
<a name="l00184"></a>00184 <span class="comment"> * &amp;amp; LDA.sh scripts that launch the hadoop-streaming job for doing</span>
<a name="l00185"></a>00185 <span class="comment"> * the distributed inference. Another script that helps you to organize</span>
<a name="l00186"></a>00186 <span class="comment"> * your corpus on hdfs is splitter.sh&lt;/P&gt;</span>
<a name="l00187"></a>00187 <span class="comment"> * &lt;P/&gt;</span>
<a name="l00188"></a>00188 <span class="comment"> * &lt;H1 CLASS=&quot;western&quot;&gt;How do I use Y! LDA?&lt;/H1&gt;</span>
<a name="l00189"></a>00189 <span class="comment"> * \ref usage</span>
<a name="l00190"></a>00190 <span class="comment"> * &lt;P/&gt;</span>
<a name="l00191"></a>00191 <span class="comment"> * &lt;H1 CLASS=&quot;western&quot;&gt;Where to find the developer documentation?&lt;/H1&gt;</span>
<a name="l00192"></a>00192 <span class="comment"> * \ref architecture &amp; the code documentation made available through</span>
<a name="l00193"></a>00193 <span class="comment"> * Doxygen</span>
<a name="l00194"></a>00194 <span class="comment"> * &lt;P/&gt;</span>
<a name="l00195"></a>00195 <span class="comment"> */</span>
</pre></div></div>
<hr class="footer"/><address style="text-align: right;"><small>Generated on Tue Jul 19 11:45:24 2011 for Y!LDA by&nbsp;
<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.6.3 </small></address>
</body>
</html>
